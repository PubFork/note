CrawlSpider类
=

[收藏说明地址](file:///Users/linan/www/scrapy_doc_chs/build/html/topics/spiders.html#crawlspider)


#### rules

一个包含一个(或多个) Rule 对象的集合(list)。 每个 Rule 对爬取网站的动作定义了特定表现。 Rule对象在下边会介绍。 如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。



#### parse_start_url(response)

当start_url的请求返回时，该方法被调用。 该方法分析最初的返回值并必须返回一个 Item 对象或者 一个 Request 对象或者 一个可迭代的包含二者对象。

##### [Link Extractor](file:///Users/linan/www/scrapy_doc_chs/build/html/topics/link-extractors.html#topics-link-extractors) 

是用来根据正则来爬去网页中特定链接的。

XMLFeedSpider
=

##### [手册地址](file:///Users/linan/www/scrapy_doc_chs/build/html/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider)

XMLFeedSpider被设计用于通过迭代各个节点来分析XML源(XML feed)。 迭代器可以从 iternodes ， xml ， html 选择。 鉴于 xml 以及 html 迭代器需要先读取所有DOM再分析而引起的性能问题， 一般还是推荐使用 iternodes 。 不过使用 html 作为迭代器能有效应对错误的XML。

